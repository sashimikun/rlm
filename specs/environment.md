# Environment Specification

## Purpose
The Environment is a sandboxed execution context where the code generated by the LLM runs. It must be persistent across iterations of a single RLM session to maintain state (variables defined in one step should be available in the next).

## Requirements

1.  **Code Execution**:
    - Capable of executing Python code dynamically (e.g., using `exec`).
    - Must capture standard output (`stdout`) and standard error (`stderr`).
    - Must maintain a namespace (globals/locals) that persists between executions.

2.  **Isolation (Optional but Recommended)**:
    - In a full system, execution should happen in a sandboxed container (Docker, etc.).
    - In a simplified system, local execution with restricted globals is acceptable but carries security risks.

3.  **Interface Injection**:
    - The environment must be pre-populated with specific helper functions:
        - `llm_query(prompt)`: To enable recursion.
        - `FINAL_VAR(var_name)`: To allow returning a variable's value as the final answer.

4.  **State Inspection**:
    - After execution, the system should be able to inspect the modified local variables to report them or return them as part of the result.

## Life Cycle

1.  **Initialization**:
    - A fresh environment is created for each RLM `completion` call.
    - Globals are initialized (e.g., `__builtins__`, injected functions).

2.  **Execution Step**:
    - Receives a code string.
    - Executes it within the existing scope.
    - Captures output and errors.
    - Updates scope with new variables.

3.  **Cleanup**:
    - Resources (temp files, processes) are released when the RLM session ends.
