# Core Concepts

## Recursive Language Models (RLM)
An RLM is an inference paradigm where a Language Model (LLM) can programmatically decompose tasks and recursively call itself. Unlike standard chains or DAGs, the RLM allows the model to decide *at runtime* whether and how to invoke sub-calls.

## Key Entities

### 1. Agent (ToolLoopAgent)
The central entity that drives the execution loop. It:
- Maintains conversation history.
- Invokes the LLM.
- Parses responses for tool calls (specifically code execution).
- Executes tools.
- Decides when to terminate (Stop Condition).

### 2. Tools
Discrete units of functionality exposed to the Agent.
- **PythonREPL**: The primary tool for RLM. It executes Python code generated by the Agent.
- **Recursion**: The `PythonREPL` environment is special because it injects an `llm_query` function into the execution scope, allowing the code to call the Agent (or a new Agent instance) again.

### 3. Environment (REPL)
The sandbox where code runs.
- **State**: Maintains variables (`locals`, `globals`) across multiple turns of the same completion request.
- **Context**: Can be pre-loaded with data (documents, tables) for the code to process.

### 4. Recursion
The defining feature.
- **Depth**: Sub-calls increase depth.
- **Limit**: Max depth prevents infinite recursion.
